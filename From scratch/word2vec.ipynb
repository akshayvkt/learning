{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Machine learning is the study of computer algorithms that \\\n",
    "improve automatically through experience. It is seen as a \\\n",
    "subset of artificial intelligence. Machine learning algorithms \\\n",
    "build a mathematical model based on sample data, known as \\\n",
    "training data, in order to make predictions or decisions without \\\n",
    "being explicitly programmed to do so. Machine learning algorithms \\\n",
    "are used in a wide variety of applications, such as email filtering \\\n",
    "and computer vision, where it is difficult or infeasible to develop \\\n",
    "conventional algorithms to perform the needed tasks.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting text corpus into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    pattern = re.compile(r'[A-Za-z]+[\\w^\\']*|[\\w^\\']*[A-Za-z]+[\\w^\\']*')\n",
    "    return pattern.findall(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how', 's', 'it', 'go', 'ing', 'ma', 'e']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(\"How*s it go-ing ma%e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['machine',\n",
       " 'learning',\n",
       " 'is',\n",
       " 'the',\n",
       " 'study',\n",
       " 'of',\n",
       " 'computer',\n",
       " 'algorithms',\n",
       " 'that',\n",
       " 'improve',\n",
       " 'automatically',\n",
       " 'through',\n",
       " 'experience',\n",
       " 'it',\n",
       " 'is',\n",
       " 'seen',\n",
       " 'as',\n",
       " 'a',\n",
       " 'subset',\n",
       " 'of',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'algorithms',\n",
       " 'build',\n",
       " 'a',\n",
       " 'mathematical',\n",
       " 'model',\n",
       " 'based',\n",
       " 'on',\n",
       " 'sample',\n",
       " 'data',\n",
       " 'known',\n",
       " 'as',\n",
       " 'training',\n",
       " 'data',\n",
       " 'in',\n",
       " 'order',\n",
       " 'to',\n",
       " 'make',\n",
       " 'predictions',\n",
       " 'or',\n",
       " 'decisions',\n",
       " 'without',\n",
       " 'being',\n",
       " 'explicitly',\n",
       " 'programmed',\n",
       " 'to',\n",
       " 'do',\n",
       " 'so',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'algorithms',\n",
       " 'are',\n",
       " 'used',\n",
       " 'in',\n",
       " 'a',\n",
       " 'wide',\n",
       " 'variety',\n",
       " 'of',\n",
       " 'applications',\n",
       " 'such',\n",
       " 'as',\n",
       " 'email',\n",
       " 'filtering',\n",
       " 'and',\n",
       " 'computer',\n",
       " 'vision',\n",
       " 'where',\n",
       " 'it',\n",
       " 'is',\n",
       " 'difficult',\n",
       " 'or',\n",
       " 'infeasible',\n",
       " 'to',\n",
       " 'develop',\n",
       " 'conventional',\n",
       " 'algorithms',\n",
       " 'to',\n",
       " 'perform',\n",
       " 'the',\n",
       " 'needed',\n",
       " 'tasks']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a mapping from tokens to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping(tokens):\n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "\n",
    "    for i, token in enumerate(set(tokens)):\n",
    "        word_to_id[token] = i\n",
    "        id_to_word[i] = token\n",
    "\n",
    "    return word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id, id_to_word = mapping(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tasks': 0,\n",
       " 'automatically': 1,\n",
       " 'the': 2,\n",
       " 'build': 3,\n",
       " 'do': 4,\n",
       " 'learning': 5,\n",
       " 'order': 6,\n",
       " 'being': 7,\n",
       " 'and': 8,\n",
       " 'conventional': 9,\n",
       " 'needed': 10,\n",
       " 'it': 11,\n",
       " 'infeasible': 12,\n",
       " 'wide': 13,\n",
       " 'variety': 14,\n",
       " 'to': 15,\n",
       " 'predictions': 16,\n",
       " 'as': 17,\n",
       " 'through': 18,\n",
       " 'computer': 19,\n",
       " 'on': 20,\n",
       " 'data': 21,\n",
       " 'based': 22,\n",
       " 'artificial': 23,\n",
       " 'programmed': 24,\n",
       " 'a': 25,\n",
       " 'mathematical': 26,\n",
       " 'decisions': 27,\n",
       " 'algorithms': 28,\n",
       " 'perform': 29,\n",
       " 'machine': 30,\n",
       " 'difficult': 31,\n",
       " 'model': 32,\n",
       " 'used': 33,\n",
       " 'explicitly': 34,\n",
       " 'email': 35,\n",
       " 'so': 36,\n",
       " 'improve': 37,\n",
       " 'known': 38,\n",
       " 'of': 39,\n",
       " 'are': 40,\n",
       " 'without': 41,\n",
       " 'intelligence': 42,\n",
       " 'filtering': 43,\n",
       " 'study': 44,\n",
       " 'make': 45,\n",
       " 'is': 46,\n",
       " 'experience': 47,\n",
       " 'where': 48,\n",
       " 'vision': 49,\n",
       " 'or': 50,\n",
       " 'such': 51,\n",
       " 'in': 52,\n",
       " 'subset': 53,\n",
       " 'applications': 54,\n",
       " 'that': 55,\n",
       " 'sample': 56,\n",
       " 'training': 57,\n",
       " 'seen': 58,\n",
       " 'develop': 59}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the 1HE matrices for inputs and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `yield from` itself starts a inner loop for each of the iterables, and yields the items of that iterable one-by-one. So the complexity here can be simplified to O(mxn) where m is number of iterables and n is # of items in each loop, or further simplified to O(T) where T is the total number of elements when we count all items from all iterables.\n",
    "\n",
    "Think of the concat function as running a for loop within a for loop to iterate through a list of lists, processing each element within a list exactly one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(*iterables):\n",
    "    for iterable in iterables:\n",
    "        yield from iterable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for 1HE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(id,vocab_size):\n",
    "    res = [0]*vocab_size\n",
    "    res[id] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tokens = len(tokens)\n",
    "n_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are we doing below?\n",
    "- We create two sets of 1HE arrays, one array containing the 1HE arrays for index of our inputs in the vocab, and the other array containing the 1HE arrays for indices of our values (aka the tokens within the window of our input).\n",
    "\n",
    "#### How do we do this? \n",
    "- We iterate through all our tokens first\n",
    "\n",
    "#### Things to keep in mind\n",
    "- A token's position in the list of tokens is not the same as its position in the vocab list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(tokens,word_to_id,window_size):\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    token_len = len(tokens)\n",
    "    vocab_size = len(word_to_id)\n",
    "    for index in range(token_len):\n",
    "        ## Create a list containing i and elements within its window\n",
    "        window = concat(range(max(0,index-window_size),index),range(index,min(token_len,index+window_size+1)))\n",
    "\n",
    "        for value_index in window:\n",
    "            if index==value_index:\n",
    "                ## we are skipping when i==j because a value can't be its own input\n",
    "                ## values are items in the window that are before/after the item, but not itself\n",
    "                continue\n",
    "            # X are inputs, y are values\n",
    "            # For first and last token, there's only two values\n",
    "            # For second and penultimate token, there's 3 values\n",
    "            # For the rest 80 tokens, there's 4 values, i.e., 2 before them and 2 after\n",
    "            # These add up to 2*2 + 3*2 + 4*80 which is equal to 330, the shape[0] of X and Y\n",
    "            # 60 aka the shape[1] of X and y is the size of our vocab\n",
    "            X.append(one_hot_encode(word_to_id[tokens[index]],vocab_size))\n",
    "            y.append(one_hot_encode(word_to_id[tokens[value_index]],vocab_size))\n",
    "\n",
    "    return np.asarray(X),np.asarray(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = generate_training_data(tokens,word_to_id,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Embedding Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's happening in this neural network and its two layers?\n",
    "\n",
    "- We feed the 1HE matrix of our sentence with each row being the word's 1HE representation.\n",
    "\n",
    "**First layer**: Multiplying with this weight matrix is what produces our embedding matrix.\n",
    "- This is then matmul'd with a weight matrix which converts this sparse 1HE matrix into a dense embedding matrix, where each row is that token's embedding vector.\n",
    "- Essentially, this first weight matrix is an embedding look-up table, where each row is a token's enbedding vector and the # of columns is the dimension of the embedding space.\n",
    "\n",
    "**Second layer**: Why do we multiply with a second weight matrix?\n",
    "- This multiplication is to convert our embedding matrix into a matrix which contains the logits for its relation to other tokens in our embedding space. Let's call this output matrix B.\n",
    "- When we then apply softmax on top on this output B, that's when we get our final output matrix, where each row contains the probabilities for different tokens, with each probability indicating how related that token is to our input token (aka how contextually related is this to our input token)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initializing the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_network(vocab_size,n_embedding):\n",
    "\n",
    "    model = {\n",
    "        'w1': np.random.randn(vocab_size,n_embedding),\n",
    "        # Why is shape of w2 this? because the output needs to have vocab_size columns, where each column\n",
    "        #indicates the probability indicates how much that token is contextually related to our input token.\n",
    "        'w2': np.random.randn(n_embedding,vocab_size)\n",
    "    }\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_network(len(word_to_id),10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward propogation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've built the softmax the way it is below, because X will be a matrix containing the vectors (aka logits), and since we want to operate softmax on multi-dimensional vectors specifically, we apply softmax on the vectors, not the matrix containing the vectors (logits).\n",
    "\n",
    "Softmax converts logits into probabilities, which is what we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    result = []\n",
    "    for x in X:\n",
    "        exp = np.exp(x)\n",
    "        result.append(exp/exp.sum())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the above softmax function doing?**\n",
    "\n",
    "If X is a matrix of multi-dim vectors and an x in it is that multi-dim vector, say [[3,4,5]], then when we apply `np.exp(x)`, it calculates $e^x$ values for each x in the vector. \n",
    "Then when we apply `exp.sum()` it calculates the sum of all these exponentials.\n",
    "Hence, when we apply exp/exp.sum(), it gives us \n",
    "**$e^i/\\sum_{n=1}^{N} e^i$**, which is the formula for softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(model, X, return_cache=True):\n",
    "    cache = {}\n",
    "\n",
    "    cache['a1'] = X @ model['w1']\n",
    "    cache['a2'] = cache['a1'] @ model['w2']\n",
    "    cache['z'] = softmax(cache['a2'])\n",
    "\n",
    "    if not return_cache:\n",
    "        ## This is during inference where we only care about the context probabilities\n",
    "        return cache['z']\n",
    "    \n",
    "    ## This is during training where we need all the intermediate activation values to later perform backprop\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((330, 10), (330, 60))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X@model['w1']).shape, ((X@model['w1'])@model['w2']).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A1=XW_1$$\n",
    "\n",
    "$$A_2=A_1W_2 $$\n",
    "\n",
    "$$Z=σ(A_2)$$ \n",
    "<p align='center'>where σ refers to the softmax function.</p>\n",
    "\n",
    "<p align='center'>The loss function w.r.t the activations A2 is given by </p>\n",
    "\n",
    "\n",
    "$$ \\frac{\\partial L}{\\partial A_2} = Z - y $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(z,y):\n",
    "    # Here y is our actual target value and z is the predicted probability value for our target\n",
    "    return -np.sum(y * np.log(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of backrpopogation, he **loss** is implicitly involved in calculating these gradients but doesn't need to be explicitly calculated as a standalone value for the purpose of updating the weights.\n",
    "\n",
    "The main reason we calculate loss is for monitoring how our model training is progressing (or regressing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(model, X, y, alpha):\n",
    "    cache = forward(model, X)\n",
    "\n",
    "    ## For all the below variables where it says dX, it just means it is the differential of loss(L) wrt X.\n",
    "    ## i.e., it is shorthand for dL/dX\n",
    "\n",
    "    ## And as we know, the caches are basically the values calculated for activations during forward prop\n",
    "\n",
    "    ## I just proved to myself all the below differentials. They're very easy to do using chain rule - try it out!\n",
    "    da2 = cache['z'] - y\n",
    "    dw2 = cache['a1'].T @ da2\n",
    "    da1 = da2@model['w2'].T\n",
    "    dw1 = X.T @ da1\n",
    "\n",
    "    assert(dw2.shape == model['w2'].shape)\n",
    "    assert(dw1.shape == model['w1'].shape)\n",
    "\n",
    "    model['w1'] -= alpha*dw1\n",
    "    model['w2'] -= alpha*dw2\n",
    "\n",
    "    return cross_entropy(cache['z'],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yk/w45pp5lj3s91zzwz55_2kqkm0000gn/T/ipykernel_26749/3326201517.py:7: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use(\"seaborn\")\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"490.04375pt\" height=\"335.465312pt\" viewBox=\"0 0 490.04375 335.465312\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2024-02-17T19:51:15.193560</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 335.465312 \n",
       "L 490.04375 335.465312 \n",
       "L 490.04375 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 36.44375 312.12 \n",
       "L 482.84375 312.12 \n",
       "L 482.84375 7.2 \n",
       "L 36.44375 7.2 \n",
       "z\n",
       "\" style=\"fill: #eaeaf2\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 56.734659 312.12 \n",
       "L 56.734659 7.2 \n",
       "\" clip-path=\"url(#paa560f0453)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\"/>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(53.95419 326.277812) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-30\" d=\"M 266 2259 \n",
       "Q 266 3072 433 3567 \n",
       "Q 600 4063 929 4331 \n",
       "Q 1259 4600 1759 4600 \n",
       "Q 2128 4600 2406 4451 \n",
       "Q 2684 4303 2865 4023 \n",
       "Q 3047 3744 3150 3342 \n",
       "Q 3253 2941 3253 2259 \n",
       "Q 3253 1453 3087 958 \n",
       "Q 2922 463 2592 192 \n",
       "Q 2263 -78 1759 -78 \n",
       "Q 1097 -78 719 397 \n",
       "Q 266 969 266 2259 \n",
       "z\n",
       "M 844 2259 \n",
       "Q 844 1131 1108 757 \n",
       "Q 1372 384 1759 384 \n",
       "Q 2147 384 2411 759 \n",
       "Q 2675 1134 2675 2259 \n",
       "Q 2675 3391 2411 3762 \n",
       "Q 2147 4134 1753 4134 \n",
       "Q 1366 4134 1134 3806 \n",
       "Q 844 3388 844 2259 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 139.554696 312.12 \n",
       "L 139.554696 7.2 \n",
       "\" clip-path=\"url(#paa560f0453)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\"/>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 10 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(133.993759 326.277812) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-31\" d=\"M 2384 0 \n",
       "L 1822 0 \n",
       "L 1822 3584 \n",
       "Q 1619 3391 1289 3197 \n",
       "Q 959 3003 697 2906 \n",
       "L 697 3450 \n",
       "Q 1169 3672 1522 3987 \n",
       "Q 1875 4303 2022 4600 \n",
       "L 2384 4600 \n",
       "L 2384 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 222.374733 312.12 \n",
       "L 222.374733 7.2 \n",
       "\" clip-path=\"url(#paa560f0453)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\"/>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 20 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(216.813796 326.277812) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-32\" d=\"M 3222 541 \n",
       "L 3222 0 \n",
       "L 194 0 \n",
       "Q 188 203 259 391 \n",
       "Q 375 700 629 1000 \n",
       "Q 884 1300 1366 1694 \n",
       "Q 2113 2306 2375 2664 \n",
       "Q 2638 3022 2638 3341 \n",
       "Q 2638 3675 2398 3904 \n",
       "Q 2159 4134 1775 4134 \n",
       "Q 1369 4134 1125 3890 \n",
       "Q 881 3647 878 3216 \n",
       "L 300 3275 \n",
       "Q 359 3922 746 4261 \n",
       "Q 1134 4600 1788 4600 \n",
       "Q 2447 4600 2831 4234 \n",
       "Q 3216 3869 3216 3328 \n",
       "Q 3216 3053 3103 2787 \n",
       "Q 2991 2522 2730 2228 \n",
       "Q 2469 1934 1863 1422 \n",
       "Q 1356 997 1212 845 \n",
       "Q 1069 694 975 541 \n",
       "L 3222 541 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 305.19477 312.12 \n",
       "L 305.19477 7.2 \n",
       "\" clip-path=\"url(#paa560f0453)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\"/>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 30 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(299.633833 326.277812) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-33\" d=\"M 269 1209 \n",
       "L 831 1284 \n",
       "Q 928 806 1161 595 \n",
       "Q 1394 384 1728 384 \n",
       "Q 2125 384 2398 659 \n",
       "Q 2672 934 2672 1341 \n",
       "Q 2672 1728 2419 1979 \n",
       "Q 2166 2231 1775 2231 \n",
       "Q 1616 2231 1378 2169 \n",
       "L 1441 2663 \n",
       "Q 1497 2656 1531 2656 \n",
       "Q 1891 2656 2178 2843 \n",
       "Q 2466 3031 2466 3422 \n",
       "Q 2466 3731 2256 3934 \n",
       "Q 2047 4138 1716 4138 \n",
       "Q 1388 4138 1169 3931 \n",
       "Q 950 3725 888 3313 \n",
       "L 325 3413 \n",
       "Q 428 3978 793 4289 \n",
       "Q 1159 4600 1703 4600 \n",
       "Q 2078 4600 2393 4439 \n",
       "Q 2709 4278 2876 4000 \n",
       "Q 3044 3722 3044 3409 \n",
       "Q 3044 3113 2884 2869 \n",
       "Q 2725 2625 2413 2481 \n",
       "Q 2819 2388 3044 2092 \n",
       "Q 3269 1797 3269 1353 \n",
       "Q 3269 753 2831 336 \n",
       "Q 2394 -81 1725 -81 \n",
       "Q 1122 -81 723 278 \n",
       "Q 325 638 269 1209 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-33\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 388.014808 312.12 \n",
       "L 388.014808 7.2 \n",
       "\" clip-path=\"url(#paa560f0453)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\"/>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 40 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(382.45387 326.277812) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-34\" d=\"M 2069 0 \n",
       "L 2069 1097 \n",
       "L 81 1097 \n",
       "L 81 1613 \n",
       "L 2172 4581 \n",
       "L 2631 4581 \n",
       "L 2631 1613 \n",
       "L 3250 1613 \n",
       "L 3250 1097 \n",
       "L 2631 1097 \n",
       "L 2631 0 \n",
       "L 2069 0 \n",
       "z\n",
       "M 2069 1613 \n",
       "L 2069 3678 \n",
       "L 634 1613 \n",
       "L 2069 1613 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-34\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 470.834845 312.12 \n",
       "L 470.834845 7.2 \n",
       "\" clip-path=\"url(#paa560f0453)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\"/>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 50 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(465.273907 326.277812) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-35\" d=\"M 266 1200 \n",
       "L 856 1250 \n",
       "Q 922 819 1161 601 \n",
       "Q 1400 384 1738 384 \n",
       "Q 2144 384 2425 690 \n",
       "Q 2706 997 2706 1503 \n",
       "Q 2706 1984 2436 2262 \n",
       "Q 2166 2541 1728 2541 \n",
       "Q 1456 2541 1237 2417 \n",
       "Q 1019 2294 894 2097 \n",
       "L 366 2166 \n",
       "L 809 4519 \n",
       "L 3088 4519 \n",
       "L 3088 3981 \n",
       "L 1259 3981 \n",
       "L 1013 2750 \n",
       "Q 1425 3038 1878 3038 \n",
       "Q 2478 3038 2890 2622 \n",
       "Q 3303 2206 3303 1553 \n",
       "Q 3303 931 2941 478 \n",
       "Q 2500 -78 1738 -78 \n",
       "Q 1113 -78 717 272 \n",
       "Q 322 622 266 1200 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-35\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 36.44375 285.993673 \n",
       "L 482.84375 285.993673 \n",
       "\" clip-path=\"url(#paa560f0453)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\"/>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 750 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(12.760938 289.57258) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-37\" d=\"M 303 3981 \n",
       "L 303 4522 \n",
       "L 3269 4522 \n",
       "L 3269 4084 \n",
       "Q 2831 3619 2401 2847 \n",
       "Q 1972 2075 1738 1259 \n",
       "Q 1569 684 1522 0 \n",
       "L 944 0 \n",
       "Q 953 541 1156 1306 \n",
       "Q 1359 2072 1739 2783 \n",
       "Q 2119 3494 2547 3981 \n",
       "L 303 3981 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-37\"/>\n",
       "       <use xlink:href=\"#ArialMT-35\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path d=\"M 36.44375 250.249636 \n",
       "L 482.84375 250.249636 \n",
       "\" clip-path=\"url(#paa560f0453)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\"/>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 1000 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(7.2 253.828542) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"166.845703\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path d=\"M 36.44375 214.505598 \n",
       "L 482.84375 214.505598 \n",
       "\" clip-path=\"url(#paa560f0453)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_18\"/>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 1250 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(7.2 218.084505) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-32\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-35\" x=\"111.230469\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"166.845703\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path d=\"M 36.44375 178.761561 \n",
       "L 482.84375 178.761561 \n",
       "\" clip-path=\"url(#paa560f0453)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_20\"/>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 1500 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(7.2 182.340467) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-35\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"166.845703\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_21\">\n",
       "      <path d=\"M 36.44375 143.017524 \n",
       "L 482.84375 143.017524 \n",
       "\" clip-path=\"url(#paa560f0453)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_22\"/>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 1750 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(7.2 146.59643) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-37\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-35\" x=\"111.230469\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"166.845703\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_23\">\n",
       "      <path d=\"M 36.44375 107.273486 \n",
       "L 482.84375 107.273486 \n",
       "\" clip-path=\"url(#paa560f0453)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_24\"/>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 2000 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(7.2 110.852392) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"166.845703\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_25\">\n",
       "      <path d=\"M 36.44375 71.529449 \n",
       "L 482.84375 71.529449 \n",
       "\" clip-path=\"url(#paa560f0453)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_26\"/>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 2250 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(7.2 75.108355) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-32\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-35\" x=\"111.230469\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"166.845703\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_27\">\n",
       "      <path d=\"M 36.44375 35.785411 \n",
       "L 482.84375 35.785411 \n",
       "\" clip-path=\"url(#paa560f0453)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_28\"/>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 2500 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(7.2 39.364317) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-35\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"166.845703\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_29\">\n",
       "    <path d=\"M 56.734659 21.06 \n",
       "L 65.016663 156.223212 \n",
       "L 73.298667 195.927521 \n",
       "L 81.58067 214.600716 \n",
       "L 89.862674 226.735694 \n",
       "L 98.144678 235.740264 \n",
       "L 106.426681 242.973703 \n",
       "L 114.708685 249.100153 \n",
       "L 122.990689 254.441287 \n",
       "L 131.272692 259.156071 \n",
       "L 139.554696 263.332865 \n",
       "L 147.8367 267.04771 \n",
       "L 156.118704 270.367117 \n",
       "L 164.400707 273.338711 \n",
       "L 172.682711 275.997424 \n",
       "L 180.964715 278.371508 \n",
       "L 189.246718 280.434611 \n",
       "L 197.528722 282.084005 \n",
       "L 205.810726 282.411366 \n",
       "L 214.09273 284.028293 \n",
       "L 222.374733 283.531282 \n",
       "L 230.656737 287.531534 \n",
       "L 238.938741 289.222617 \n",
       "L 247.220744 289.49999 \n",
       "L 255.502748 287.621918 \n",
       "L 263.784752 291.224059 \n",
       "L 272.066756 293.208755 \n",
       "L 280.348759 293.081042 \n",
       "L 288.630763 291.002803 \n",
       "L 296.912767 293.657208 \n",
       "L 305.19477 294.577308 \n",
       "L 313.476774 294.257784 \n",
       "L 321.758778 291.221081 \n",
       "L 330.040782 294.791149 \n",
       "L 338.322785 296.413322 \n",
       "L 346.604789 296.422151 \n",
       "L 354.886793 297.187734 \n",
       "L 363.168796 296.710391 \n",
       "L 371.4508 297.180372 \n",
       "L 379.732804 296.208236 \n",
       "L 388.014808 297.321505 \n",
       "L 396.296811 296.482411 \n",
       "L 404.578815 297.077194 \n",
       "L 412.860819 296.190604 \n",
       "L 421.142822 297.397839 \n",
       "L 429.424826 295.68802 \n",
       "L 437.70683 297.100541 \n",
       "L 445.988833 296.380137 \n",
       "L 454.270837 298.26 \n",
       "L 462.552841 296.677187 \n",
       "\" clip-path=\"url(#paa560f0453)\" style=\"fill: none; stroke: #87ceeb; stroke-width: 1.75; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 36.44375 312.12 \n",
       "L 36.44375 7.2 \n",
       "\" style=\"fill: none\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 482.84375 312.12 \n",
       "L 482.84375 7.2 \n",
       "\" style=\"fill: none\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 36.44375 312.12 \n",
       "L 482.84375 312.12 \n",
       "\" style=\"fill: none\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 36.44375 7.2 \n",
       "L 482.84375 7.2 \n",
       "\" style=\"fill: none\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"paa560f0453\">\n",
       "   <rect x=\"36.44375\" y=\"7.2\" width=\"446.4\" height=\"304.92\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_iter = 50\n",
    "learning_rate = 0.05\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "history = [backward(model, X, y, learning_rate) for _ in range(n_iter)]\n",
    "\n",
    "plt.plot(range(len(history)), history, color=\"skyblue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empirically testing how well it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning = one_hot_encode(word_to_id['machine'], len(word_to_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = forward(model, [learning], return_cache=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.57868972e-03, 1.27552800e-03, 9.29229383e-07, 2.69099629e-04,\n",
       "       5.61487694e-05, 1.57197404e-03, 1.06336723e-03, 6.79025882e-04,\n",
       "       1.37676993e-04, 7.62427156e-02, 7.43875115e-08, 1.70824788e-04,\n",
       "       7.21863987e-04, 8.50335779e-04, 5.19431744e-06, 1.64724488e-04,\n",
       "       2.32472251e-02, 4.78055744e-05, 3.03254524e-07, 2.28893071e-06,\n",
       "       1.67472799e-03, 4.05573932e-04, 3.38607622e-04, 8.15572754e-04,\n",
       "       2.24766972e-04, 3.09637837e-04, 9.51846715e-06, 1.14723622e-03,\n",
       "       4.87207856e-04, 6.85376393e-07, 1.24729980e-04, 3.67904700e-01,\n",
       "       3.89433689e-01, 9.34191679e-07, 2.75927109e-02, 2.63795068e-07,\n",
       "       3.56376712e-05, 4.53774001e-02, 4.19693834e-04, 2.17157334e-06,\n",
       "       2.62591102e-04, 1.99263192e-04, 4.19128046e-05, 2.74255928e-04,\n",
       "       2.63482823e-05, 4.93554666e-05, 2.18642872e-02, 4.03270716e-05,\n",
       "       1.48851464e-04, 2.03620557e-05, 6.61660220e-06, 2.94409642e-02,\n",
       "       5.08572772e-07, 2.43759018e-06, 5.66589598e-04, 1.16517682e-03,\n",
       "       2.70922901e-04, 1.04175053e-05, 1.15059681e-04, 1.02490068e-04])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Machine learning is the study of computer algorithms that \\\n",
    "improve automatically through experience. It is seen as a \\\n",
    "subset of artificial intelligence. Machine learning algorithms \\\n",
    "build a mathematical model based on sample data, known as \\\n",
    "training data, in order to make predictions or decisions without \\\n",
    "being explicitly programmed to do so. Machine learning algorithms \\\n",
    "are used in a wide variety of applications, such as email filtering \\\n",
    "and computer vision, where it is difficult or infeasible to develop \\\n",
    "conventional algorithms to perform the needed tasks.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 closest is learning\n",
      "1 closest is algorithms\n",
      "2 closest is artificial\n",
      "3 closest is do\n",
      "4 closest is is\n",
      "5 closest is so\n",
      "6 closest is to\n",
      "7 closest is intelligence\n",
      "8 closest is machine\n",
      "9 closest is used\n",
      "10 closest is infeasible\n",
      "11 closest is computer\n",
      "12 closest is conventional\n",
      "13 closest is the\n",
      "14 closest is of\n",
      "15 closest is being\n",
      "16 closest is subset\n",
      "17 closest is as\n",
      "18 closest is and\n",
      "19 closest is predictions\n",
      "20 closest is tasks\n",
      "21 closest is make\n",
      "22 closest is build\n",
      "23 closest is study\n",
      "24 closest is perform\n",
      "25 closest is explicitly\n",
      "26 closest is without\n",
      "27 closest is filtering\n",
      "28 closest is vision\n",
      "29 closest is order\n",
      "30 closest is develop\n",
      "31 closest is difficult\n",
      "32 closest is variety\n",
      "33 closest is seen\n",
      "34 closest is where\n",
      "35 closest is are\n",
      "36 closest is wide\n",
      "37 closest is email\n",
      "38 closest is in\n",
      "39 closest is such\n",
      "40 closest is automatically\n",
      "41 closest is applications\n",
      "42 closest is that\n",
      "43 closest is mathematical\n",
      "44 closest is through\n",
      "45 closest is decisions\n",
      "46 closest is model\n",
      "47 closest is improve\n",
      "48 closest is a\n",
      "49 closest is programmed\n",
      "50 closest is it\n",
      "51 closest is training\n",
      "52 closest is known\n",
      "53 closest is or\n",
      "54 closest is sample\n",
      "55 closest is on\n",
      "56 closest is based\n",
      "57 closest is needed\n",
      "58 closest is experience\n",
      "59 closest is data\n"
     ]
    }
   ],
   "source": [
    "for index,word in enumerate((id_to_word[id] for id in np.argsort(result)[::-1])):\n",
    "    print(f\"{index} closest is {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.22282817e-01, -5.36043478e-01, -1.75051356e+00,\n",
       "         8.46215410e-01, -1.15719347e+00,  9.39692730e-01,\n",
       "         9.50404975e-01, -4.75466933e-01, -5.39593711e-01,\n",
       "        -1.11465964e+00],\n",
       "       [ 3.61381098e-01, -3.84275073e-01, -1.05460733e+00,\n",
       "        -2.40563689e+00, -1.97408973e+00,  4.05118962e-01,\n",
       "        -1.21907488e-02,  1.68787023e+00, -1.02087839e+00,\n",
       "        -9.88432133e-01],\n",
       "       [-5.06258743e-01,  3.90917645e-01,  7.85735641e-01,\n",
       "        -2.04384929e+00,  7.73863866e-01, -1.48260801e+00,\n",
       "        -1.43801298e-01,  1.30190877e+00,  8.24752771e-01,\n",
       "        -7.63187585e-01],\n",
       "       [-6.28499989e-01,  2.18281708e+00, -8.08091662e-01,\n",
       "        -1.61487327e+00,  9.85772160e-02,  1.21552773e-01,\n",
       "         2.13717651e+00, -1.32549533e+00, -9.18259761e-01,\n",
       "        -4.13627769e-01],\n",
       "       [ 5.94929711e-01, -4.96253425e-01,  1.39242486e+00,\n",
       "         4.40682293e-01, -1.59958313e+00, -5.49698962e-01,\n",
       "         1.38471963e+00,  1.28409968e+00,  1.23833658e+00,\n",
       "        -1.73813851e-01],\n",
       "       [ 7.72014766e-01, -1.04482560e+00, -2.89770568e-02,\n",
       "         6.19834780e-01,  2.11229548e-01, -2.66114929e-01,\n",
       "        -1.52239131e+00, -1.88103883e+00,  8.23731227e-01,\n",
       "         2.84915766e-01],\n",
       "       [ 1.59381676e+00,  9.87472921e-02, -6.78467366e-01,\n",
       "         5.50562589e-02,  5.25540429e-01,  7.96259485e-01,\n",
       "         9.77404051e-01,  1.08992654e+00, -1.62700745e+00,\n",
       "         8.33107471e-01],\n",
       "       [-1.52163531e-01,  6.15921485e-01,  8.06713373e-01,\n",
       "        -1.46845109e+00, -1.18480492e+00,  1.27087055e+00,\n",
       "         2.35396638e+00,  1.43086204e-01, -6.38608605e-01,\n",
       "        -1.85675144e-02],\n",
       "       [-1.30016326e-01, -3.02764962e-01,  6.71745643e-01,\n",
       "        -2.01748518e+00, -9.69214066e-01, -1.24753855e-03,\n",
       "         1.15076215e+00, -9.16394211e-01,  1.95753883e-01,\n",
       "         2.38846853e-01],\n",
       "       [ 7.48679088e-01, -1.78588863e-01, -7.94193701e-01,\n",
       "         9.77527476e-01,  4.09439315e-01, -1.86239655e+00,\n",
       "         7.81984178e-01, -2.31102793e-02, -1.19485077e+00,\n",
       "        -1.61260349e+00],\n",
       "       [-1.17474643e+00,  1.35443884e+00, -8.35339216e-01,\n",
       "        -7.72038291e-01, -2.20343895e-01,  3.16549300e-01,\n",
       "         2.74392777e-01,  1.68452882e+00,  1.69551579e+00,\n",
       "        -5.56578711e-01],\n",
       "       [ 1.67280778e-02,  4.69438539e-01,  9.62504763e-01,\n",
       "        -3.74573565e-02,  3.23714516e-01,  1.88462883e-01,\n",
       "        -1.22190349e-01, -1.87270809e+00,  2.68372322e+00,\n",
       "        -3.58586403e-02],\n",
       "       [ 7.87789797e-01,  6.12958305e-01,  2.16363930e+00,\n",
       "        -5.97126468e-01,  6.41927689e-01, -3.05640924e-01,\n",
       "         1.24352088e+00,  4.33941629e-01, -1.27915469e-01,\n",
       "        -1.59408206e+00],\n",
       "       [-4.85938332e-01,  6.33414682e-02,  1.12348628e+00,\n",
       "         6.88948844e-01,  1.50405903e+00,  2.01906618e+00,\n",
       "        -1.25607827e+00, -1.29412819e+00, -3.13001518e-01,\n",
       "        -3.84833708e-01],\n",
       "       [-1.00194306e+00, -1.34204170e+00, -1.30796654e+00,\n",
       "         1.32026333e+00, -2.52632268e-01,  8.57579480e-01,\n",
       "        -9.27191884e-01, -1.37924009e+00, -1.72198564e-01,\n",
       "        -8.56870623e-01],\n",
       "       [ 1.79242179e+00, -1.10273759e-01,  1.08195461e+00,\n",
       "         8.99726011e-01,  3.61264576e-01, -8.10766454e-01,\n",
       "         6.33249904e-01,  1.71461542e+00, -7.34133614e-01,\n",
       "        -1.71575005e-02],\n",
       "       [-5.43716540e-01, -5.21758307e-02,  4.44586377e-02,\n",
       "         1.02238168e+00,  2.57420064e-01,  1.73448392e+00,\n",
       "        -5.31632708e-01, -3.36488371e-01,  3.32379670e-01,\n",
       "         7.34815988e-01],\n",
       "       [-2.42090904e+00, -1.77768573e-01,  1.04787524e+00,\n",
       "        -8.83141345e-01,  7.23564335e-01,  4.26477135e-01,\n",
       "         1.12448350e+00,  8.96964947e-01,  6.64729601e-01,\n",
       "         2.14464277e+00],\n",
       "       [ 6.53602847e-01, -8.75517045e-01, -6.23787281e-02,\n",
       "         1.97109621e-01, -7.80101820e-01,  1.33670370e+00,\n",
       "        -2.42673159e-01,  5.35454611e-01, -2.64809072e+00,\n",
       "         3.04786739e-01],\n",
       "       [-9.81221870e-01,  7.96335485e-01,  2.11890689e-01,\n",
       "         2.08640410e-01, -2.37609380e-01, -1.06145616e-01,\n",
       "        -5.31623152e-01,  1.31235970e+00,  1.69782744e+00,\n",
       "        -1.68438713e+00],\n",
       "       [ 5.08400887e-01,  4.97348572e-01,  6.07181300e-01,\n",
       "         1.35959623e+00, -1.33871483e+00, -5.88954681e-01,\n",
       "         7.43043804e-01,  1.50472798e+00,  1.34685152e+00,\n",
       "         2.84736720e+00],\n",
       "       [ 1.37360121e+00,  5.47690201e-01, -6.85130594e-01,\n",
       "         5.73433569e-01, -2.02027803e+00, -1.30402723e+00,\n",
       "         1.18207617e-01,  1.71486609e-01,  9.66931390e-01,\n",
       "        -7.38911581e-02],\n",
       "       [ 1.96499674e+00, -1.30045742e+00,  1.69845763e-01,\n",
       "        -1.33757777e+00, -1.00645881e-01, -2.10801109e-01,\n",
       "         6.78029727e-01, -1.06847710e+00, -1.75925833e+00,\n",
       "        -9.63188081e-02],\n",
       "       [ 2.12993692e+00,  1.17335158e+00, -7.18743367e-01,\n",
       "        -7.16103145e-01,  5.45312384e-01,  2.09212370e-01,\n",
       "        -1.32812607e+00, -2.69804708e-01,  2.60265106e-01,\n",
       "        -7.67894101e-01],\n",
       "       [-7.00414728e-01,  2.28528031e-01,  1.13947032e+00,\n",
       "         1.22535645e+00, -1.80085475e+00, -1.93144946e-01,\n",
       "        -3.97174463e-01,  5.70512984e-01,  1.64920812e+00,\n",
       "        -1.10707404e+00],\n",
       "       [ 2.67350656e-01,  4.01743488e-01,  1.29507965e+00,\n",
       "         6.86272448e-01, -3.02659139e+00,  5.47226357e-01,\n",
       "         3.06712880e-01, -1.05721991e+00,  1.89466133e-01,\n",
       "         1.10046147e+00],\n",
       "       [-1.24374581e+00,  9.86199506e-01, -1.76318510e+00,\n",
       "        -1.15619413e+00, -1.10925839e+00,  1.04397734e-01,\n",
       "         8.87124507e-01, -2.47051390e-01,  8.90645440e-01,\n",
       "         1.18801202e+00],\n",
       "       [ 1.60051299e+00, -1.52709153e+00,  1.19457608e+00,\n",
       "        -7.93936113e-01, -1.89380564e+00,  5.95794974e-01,\n",
       "        -7.33872189e-01, -2.61766070e-01, -2.46393016e-01,\n",
       "         3.89340709e-02],\n",
       "       [ 4.01983174e-01,  5.83449426e-01,  2.04406841e+00,\n",
       "        -1.01556200e+00,  4.46135171e-01, -9.73859260e-01,\n",
       "        -2.76124429e-01, -8.31560773e-01, -1.76642347e+00,\n",
       "         9.24916938e-01],\n",
       "       [-9.93175069e-01,  7.68272766e-01, -2.76747942e-02,\n",
       "        -5.95113182e-01,  6.07192892e-02, -2.51829499e+00,\n",
       "        -1.02030472e+00,  8.67161904e-01,  1.35161919e-01,\n",
       "        -1.17125728e-01],\n",
       "       [ 1.34857740e-01, -5.06113546e-01, -1.02975490e+00,\n",
       "         1.52570447e+00, -1.80285940e+00, -1.93659337e-01,\n",
       "         5.31084681e-01,  1.47484370e+00,  4.42813104e-01,\n",
       "        -3.44851094e-01],\n",
       "       [ 1.20938126e+00, -1.64944101e+00, -4.20412403e-01,\n",
       "         8.49351961e-01,  1.44438368e-02, -1.10099210e+00,\n",
       "         5.94524790e-01,  2.32512821e-01, -2.23870946e-02,\n",
       "         1.25773189e+00],\n",
       "       [ 4.16782922e-01,  9.11964659e-01, -4.98973853e-01,\n",
       "         8.51919720e-01, -1.23187821e+00, -4.10716262e-01,\n",
       "         1.96576325e+00, -9.24203626e-01, -6.11701492e-01,\n",
       "         3.76368546e-01],\n",
       "       [ 2.89397793e-01, -5.85211562e-01,  7.99808394e-01,\n",
       "         4.46726963e-01,  1.51873415e-01,  1.57727198e+00,\n",
       "        -5.25758816e-01, -1.17284041e+00,  7.85408658e-01,\n",
       "        -1.71798720e+00],\n",
       "       [-1.08483220e-01, -1.07202966e+00,  2.08781272e-02,\n",
       "         1.54866831e+00, -1.31342022e+00, -2.13216060e-01,\n",
       "         7.09643192e-02, -2.44763302e-01, -9.83708966e-01,\n",
       "        -9.66136349e-01],\n",
       "       [-3.05952409e-02,  4.68829328e-01, -9.16549228e-01,\n",
       "        -1.04193591e+00,  7.08748281e-02,  3.87270106e-01,\n",
       "         5.03255976e-01, -1.78428074e+00,  1.31337049e+00,\n",
       "         4.49825363e-01],\n",
       "       [ 1.06938546e+00,  1.02793280e+00, -3.24837594e-01,\n",
       "        -9.89388207e-01,  4.63545226e-01, -2.44931220e+00,\n",
       "         4.66963719e-01, -2.62336043e-01, -9.91115373e-01,\n",
       "         9.38674427e-01],\n",
       "       [-2.71342535e-01, -5.82898468e-01,  8.75759019e-01,\n",
       "         2.76747459e+00,  1.43261609e+00, -1.23226912e+00,\n",
       "         8.63726531e-01, -9.55468593e-01,  6.32781985e-01,\n",
       "        -1.78728903e-01],\n",
       "       [-2.67052787e-01, -1.37705153e+00, -4.42628762e-01,\n",
       "        -2.02965361e-01, -5.55134827e-01,  3.10809368e-01,\n",
       "        -1.13048771e+00,  2.76381713e-01,  2.26378218e+00,\n",
       "        -1.28049812e+00],\n",
       "       [-1.20025743e+00,  2.50109068e+00,  1.65377029e-01,\n",
       "         1.10130561e-01,  2.80126801e-01, -6.81399673e-01,\n",
       "        -7.48081058e-01,  1.38664877e+00,  1.64166054e-01,\n",
       "        -4.98050687e-01],\n",
       "       [-2.00697747e+00, -5.69192061e-01, -5.49918992e-01,\n",
       "        -1.66291172e+00, -6.44921879e-01,  1.39597087e+00,\n",
       "        -6.85594435e-03, -1.13342385e+00, -4.78796976e-01,\n",
       "         6.20424283e-01],\n",
       "       [ 7.65671518e-01, -9.30410276e-01, -2.11552872e+00,\n",
       "         1.57507990e+00, -1.85599609e-01,  8.14254733e-01,\n",
       "         8.07565793e-01, -5.38650423e-01,  1.88295732e+00,\n",
       "         6.32463720e-01],\n",
       "       [ 1.72288407e+00,  1.74548777e+00, -1.49269248e-01,\n",
       "         1.95832940e+00,  1.18436633e+00, -1.69800784e-01,\n",
       "        -1.53011351e+00, -6.14216837e-02, -1.91597678e-02,\n",
       "        -1.69874213e+00],\n",
       "       [-1.33632762e-01, -2.52264603e+00,  7.13362276e-02,\n",
       "         1.42894426e+00,  1.55586573e+00,  8.63745491e-01,\n",
       "         4.85238536e-01, -1.90067046e+00, -4.62831852e-01,\n",
       "        -4.87740700e-01],\n",
       "       [-1.91242791e+00,  1.96875613e-01,  1.88771320e-01,\n",
       "        -5.99370378e-02,  1.41235545e-01, -5.02411519e-01,\n",
       "         4.89764217e-02, -1.49784491e+00,  3.08014195e-01,\n",
       "         1.67617604e+00],\n",
       "       [ 1.20700992e+00,  1.60120570e+00,  7.30063108e-01,\n",
       "         3.92889827e-01, -1.14862575e+00, -1.69709564e-01,\n",
       "        -3.53987055e-02,  7.15320494e-02, -1.39377987e+00,\n",
       "        -1.80955730e+00],\n",
       "       [ 1.65929981e+00, -7.21550265e-02, -1.28189921e+00,\n",
       "         1.11339721e+00, -8.42880831e-01, -4.58916017e-01,\n",
       "         4.10034132e-02, -9.59397738e-01, -1.10589536e+00,\n",
       "        -1.00585211e+00],\n",
       "       [-3.95538109e-01, -1.61372338e+00, -2.53241834e+00,\n",
       "         3.86952855e-01,  5.60613984e-02,  1.73390965e-01,\n",
       "         5.03086593e-01, -6.37589915e-01,  1.01040455e+00,\n",
       "         3.32229304e+00],\n",
       "       [ 8.41238987e-01,  1.11162133e+00, -1.37746141e-01,\n",
       "        -1.30549915e+00, -3.20434484e-01, -5.64241961e-01,\n",
       "        -2.64673277e-01, -1.63891079e+00,  2.49374427e+00,\n",
       "         5.78189359e-02],\n",
       "       [-2.02944344e-01, -2.07137170e-01,  1.13787547e-01,\n",
       "        -4.56813626e-01,  2.09987521e+00,  5.86003179e-02,\n",
       "        -1.79951024e+00, -6.41850286e-01,  3.54873597e-01,\n",
       "        -1.90456019e+00],\n",
       "       [ 2.38771116e-01,  6.62826710e-01, -1.52587851e+00,\n",
       "         3.26386396e-01, -5.88768830e-01, -1.01422077e+00,\n",
       "        -1.17507880e-01,  1.32852421e+00, -7.37847186e-02,\n",
       "        -7.21452229e-01],\n",
       "       [-3.64516386e-01, -1.40683485e-01,  8.08156384e-02,\n",
       "        -1.34254544e+00, -1.36182025e+00, -7.33782835e-01,\n",
       "        -9.18372969e-01, -1.18563641e+00, -5.42934271e-01,\n",
       "        -7.10019171e-01],\n",
       "       [-8.74216838e-02,  1.21042206e+00, -1.76453815e+00,\n",
       "        -8.27340971e-01, -2.10044280e-01, -2.12617505e+00,\n",
       "        -8.60502509e-01,  1.20859337e+00,  1.19106373e+00,\n",
       "         4.94407853e-01],\n",
       "       [-2.85145364e-01, -2.54431125e+00,  2.96397742e-02,\n",
       "        -2.02281068e+00,  1.35509323e-01, -5.74618252e-01,\n",
       "         1.97292229e-01, -2.50042068e-01,  8.57539119e-01,\n",
       "        -1.02066617e+00],\n",
       "       [-8.21016764e-01,  1.83057838e-01,  1.41271589e+00,\n",
       "         9.26113377e-01, -1.76510717e+00, -1.33520199e-01,\n",
       "        -1.03571527e+00, -1.06396913e+00,  3.92450927e-01,\n",
       "        -1.49895759e+00],\n",
       "       [ 8.77458525e-01, -1.28430010e-01, -1.31460628e-01,\n",
       "         1.20548401e+00, -1.42185836e+00,  7.87254465e-01,\n",
       "        -5.62044883e-01, -1.17490579e+00,  8.37057487e-01,\n",
       "         7.28110953e-01],\n",
       "       [-1.13745236e+00,  1.30865765e+00,  8.34450266e-01,\n",
       "        -3.17897938e-01,  1.05089469e+00, -4.67764619e-01,\n",
       "        -2.63125721e+00, -1.09540124e+00, -1.61171955e+00,\n",
       "        -1.45816770e+00],\n",
       "       [ 4.01948373e-01,  2.08810039e+00, -2.49246071e-01,\n",
       "        -6.23384864e-01,  1.03863496e+00, -2.32219937e+00,\n",
       "         9.78597884e-01,  7.99323286e-01,  5.66145780e-01,\n",
       "         4.30777962e-01],\n",
       "       [ 2.02277412e+00, -8.58449236e-02,  5.06471521e-01,\n",
       "         1.87618885e+00,  3.93007161e-01, -5.51790388e-01,\n",
       "        -1.23445728e+00,  1.01941697e+00,  1.07721358e+00,\n",
       "        -2.26267643e-01],\n",
       "       [-3.03150129e-01,  1.68955286e+00, -1.44210620e-01,\n",
       "        -3.55355534e-01,  1.28350327e+00,  1.81191003e+00,\n",
       "         8.30207594e-01,  2.16698523e-01, -1.68391139e-01,\n",
       "        -1.07955278e+00]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['w1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60, 10), 60)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['w1'].shape, len(word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embedding(model,word):\n",
    "    try:\n",
    "        idx = word_to_id[word]\n",
    "    except KeyError:\n",
    "        print(f\"{word} not in corpus\")\n",
    "    word_onehot = one_hot_encode(idx, len(word_to_id))\n",
    "\n",
    "    # The below makes sense because cache['a1'] = X @ model['w1'], and that means that\n",
    "    # when we feed in our word which is X and it is mat-mul'd with model['w1], we \n",
    "    # get cache['a1'] which gives the embedding matrix (or vector if we're feeding only one word.)\n",
    "    return forward(model,word_onehot)['a1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.72228282, -0.53604348, -1.75051356,  0.84621541, -1.15719347,\n",
       "        0.93969273,  0.95040497, -0.47546693, -0.53959371, -1.11465964])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_embedding(model,'machine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alright, why does this actually work?**\n",
    "\n",
    "We created 2 weight matrices and updated them during training, each of which serve a specific purpose\n",
    "\n",
    "The first weight matrix helps convert our sparse 1HE matrix containing 1HE vectors for tokens, into a dense embedding matrix where each row is the embedding vector for a token.\n",
    "\n",
    "How did that come to be though?\n",
    "\n",
    "As we backpropogate the error from the second weight matrix back to the first weight matrix, what we are doing is trying to nudge this matrix in a direction that will better help us predict context in the second weight matrix. And because the other piece is literally that we are using this first weight matrix as a mapping of a sparse input token matrix into a dense matrix, a better first weight matrix just means that this improvement leads to it doing a better job at embedding these sparse vectors as well.\n",
    "\n",
    " Essentially, the embeddings are adjusted to group together words that predict similar contexts, which is why they capture semantic meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
